{
  "comments": [
    {
      "unresolved": true,
      "key": {
        "uuid": "b6b7067b_6874fe3f",
        "filename": "runtime/gc/heap.cc",
        "patchSetId": 1
      },
      "lineNbr": 3689,
      "author": {
        "id": 1258954
      },
      "writtenOn": "2021-03-11T01:53:36Z",
      "side": 1,
      "message": "I didn\u0027t get how is it possible in the current code for multiple simultaneous concurrent-GC requests to end up in multiple GCs being done?\n\nThis function returns kGcTypeNone only if there is no GC running at the same time. I must be missing something. Can you please explain.",
      "range": {
        "startLine": 3689,
        "startChar": 8,
        "endLine": 3689,
        "endChar": 27
      },
      "revId": "5426f13f119397f9f66f01cff3d8db4a7853faa2",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "f0a5703c_f32960aa",
        "filename": "runtime/gc/heap.cc",
        "patchSetId": 1
      },
      "lineNbr": 3689,
      "author": {
        "id": 1042828
      },
      "writtenOn": "2021-03-11T02:05:01Z",
      "side": 1,
      "message": "I\u0027ll fix the commit message. I think the problem is with multiple concurrent calls to CollectGarbageInternal, which can come from various sources. Multiple \"concurrent GC\" requests are generally getting filtered.\n\nIt looked to me as this was not too unlikely. If I have several threads allocating and run out of space, they\u0027re all likely to call CollectGarbageInternal(). Do you see something that would prevent that?\n\nHowever TreeHugger pointed out that I\u0027m suppressing collections more aggressively than I should be. So this CL isn\u0027t quite there yet. I also need to run some benchmarks to check for space regressions.",
      "parentUuid": "b6b7067b_6874fe3f",
      "range": {
        "startLine": 3689,
        "startChar": 8,
        "endLine": 3689,
        "endChar": 27
      },
      "revId": "5426f13f119397f9f66f01cff3d8db4a7853faa2",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "96e5d85e_c2135abb",
        "filename": "runtime/gc/heap.cc",
        "patchSetId": 1
      },
      "lineNbr": 3689,
      "author": {
        "id": 1258954
      },
      "writtenOn": "2021-03-11T03:07:12Z",
      "side": 1,
      "message": "I think the likely case is where multiple threads try to queue up several concurrent GC requests, when they observe concurrent_start_bytes_ being reached. But all the requests except for one will be dropped due to concurrent_gc_pending_ being already set to true.\n\nThe multiple sources of CollectGarbageInternal definitely exist, but doesn\u0027t seem likely to cause multiple GCs one after the other. Can you please give an example of how that can happen, even occasionally?\nEven if such a case exists, I think what we need is ConcurrentGC() be done by the calling thread, instead of adding a task for gc-thread to do asynchronously. With this, let\u0027s say a concurrent GC is already going on, and another thread tries to invoke GC due to native-alloc, then all that second thread should do is wait for the current GC to finish and then back out. And this is exactly what ConcurrentGC() does. No?",
      "parentUuid": "f0a5703c_f32960aa",
      "range": {
        "startLine": 3689,
        "startChar": 8,
        "endLine": 3689,
        "endChar": 27
      },
      "revId": "5426f13f119397f9f66f01cff3d8db4a7853faa2",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "7171a47b_546ad384",
        "filename": "runtime/gc/heap.cc",
        "patchSetId": 1
      },
      "lineNbr": 3689,
      "author": {
        "id": 1042828
      },
      "writtenOn": "2021-03-11T04:41:52Z",
      "side": 1,
      "message": "If all requests come through RequestConcurrentGC(), then I think we\u0027re more or less fine. It\u0027s probably still not perfect, with or without this CL, and that may also be worth addressing. The problem there is that we may notice we need a concurrent GC, get suspended while the current one completes, and then wake up and notice that there is no pending request any more, and enqueue a collection that was triggered based on obsolete heap statistics. I don\u0027t actually think that\u0027s terribly unlikely, though the window is hopefully pretty small; while a background GC is running we observedly get a non-stop stream of RequestConcurrentGC calls. I\u0027ve seen hundreds, and I think it can be thousands.\n\nThis CL doesn\u0027t do much about this path. It still avoids obviously redundant calls like before, with a slightly different mechanism. It may even have made the race window slightly bigger, so it should do better there.\n\nLooking at the code more carefully, I see that if all paths go through AllocateInternalWithGC(), it\u0027s also somewhat unlikely that we get multiple GCs, since we try to allocate after waiting for the previous GC. That\u0027s clearly far from foolproof, e.g. if both threads saw a minor GC in progress, but it didn\u0027t suffice for freeing up a sufficiently large object. But I agree it\u0027s not likely.\n\nThe case that\u0027s probably more likely is if we have an explicitly requested (or nearly out-of-memory) GC running, and then trigger a concurrent GC, I think the concurrent GC will just wait for the earlier blocking GC to complete, and then run immediately. Or possibly vice-versa.\n\nIn general, I think that trying to reason about all these corner cases is a mess, and we should just have a way to notice when the data on which the GC request was based is out of date, and ignore the request. I think that basically means we need to associate a time stamp with the request. If there was an intervening GC, we ignore the request. (With adjustments for the explicit case, which the current CL neglects.) That\u0027s basically what this CL tries to do, though not yet correctly. Getting unnecessary GCs, even if it\u0027s only in near OOM and explicitly requested situations, isn\u0027t good. It compounds a bad situation. The other reason it bothers me is that it potentially adds strange measurement noise, making it hard to evaluate other changes.",
      "parentUuid": "96e5d85e_c2135abb",
      "range": {
        "startLine": 3689,
        "startChar": 8,
        "endLine": 3689,
        "endChar": 27
      },
      "revId": "5426f13f119397f9f66f01cff3d8db4a7853faa2",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "f18b0208_3cc95a63",
        "filename": "runtime/gc/heap.cc",
        "patchSetId": 1
      },
      "lineNbr": 3689,
      "author": {
        "id": 1258954
      },
      "writtenOn": "2021-03-11T22:02:55Z",
      "side": 1,
      "message": "\u003e If all requests come through RequestConcurrentGC(), then I think we\u0027re more or less fine. It\u0027s probably still not perfect, with or without this CL, and that may also be worth addressing. The problem there is that we may notice we need a concurrent GC, get suspended while the current one completes, and then wake up and notice that there is no pending request any more, and enqueue a collection that was triggered based on obsolete heap statistics. I don\u0027t actually think that\u0027s terribly unlikely, though the window is hopefully pretty small; while a background GC is running we observedly get a non-stop stream of RequestConcurrentGC calls. I\u0027ve seen hundreds, and I think it can be thousands.\n\u003e \n\nWouldn\u0027t these RequestConcurrentGC calls all get neglected due to WaitForGCToComplete() as a GC is currently going on?\n\n\u003e This CL doesn\u0027t do much about this path. It still avoids obviously redundant calls like before, with a slightly different mechanism. It may even have made the race window slightly bigger, so it should do better there.\n\u003e \n\u003e Looking at the code more carefully, I see that if all paths go through AllocateInternalWithGC(), it\u0027s also somewhat unlikely that we get multiple GCs, since we try to allocate after waiting for the previous GC. That\u0027s clearly far from foolproof, e.g. if both threads saw a minor GC in progress, but it didn\u0027t suffice for freeing up a sufficiently large object. But I agree it\u0027s not likely.\n\u003e \n\u003e The case that\u0027s probably more likely is if we have an explicitly requested (or nearly out-of-memory) GC running, and then trigger a concurrent GC, I think the concurrent GC will just wait for the earlier blocking GC to complete, and then run immediately. Or possibly vice-versa.\n\nAgain, I would imagine that WaitForGcToComplete() in CollectGarbageInternal() will avoid these, no? An explicit GC gets executed by the calling thread itself, whereas the concurrent one by GC-thread. So it should be addressed, I think.\n\n\u003e \n\u003e In general, I think that trying to reason about all these corner cases is a mess, and we should just have a way to notice when the data on which the GC request was based is out of date, and ignore the request. I think that basically means we need to associate a time stamp with the request. If there was an intervening GC, we ignore the request. (With adjustments for the explicit case, which the current CL neglects.) That\u0027s basically what this CL tries to do, though not yet correctly. Getting unnecessary GCs, even if it\u0027s only in near OOM and explicitly requested situations, isn\u0027t good. It compounds a bad situation. The other reason it bothers me is that it potentially adds strange measurement noise, making it hard to evaluate other changes.\n\nWhen you put it this way, it makes sense ðŸ˜Š\n\nMy point is not that the repeated GCs are not possible. I\u0027m just saying that it seems unlikely. I think this is a problem only in cases where some thread suspends after deciding to do a GC and wakes after someone else has already done it. But the likelihood of the first thread suspending within that small window seems too small. But if I\u0027m wrong and it is indeed being observed frequently, then definitely worth fixing.\nAlso, it seems to me that the root cause of this problem that at some places GC is invoked directly by calling CollectGarbageInternal(), while others (the most frequently taken path via RequestConcurrentGC()) for the rest. Wouldn\u0027t the problem go away if all GC invocations had the similar logic as in ConcurrentGC()?",
      "parentUuid": "7171a47b_546ad384",
      "range": {
        "startLine": 3689,
        "startChar": 8,
        "endLine": 3689,
        "endChar": 27
      },
      "revId": "5426f13f119397f9f66f01cff3d8db4a7853faa2",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "9d45f57f_698f0002",
        "filename": "runtime/gc/heap.cc",
        "patchSetId": 1
      },
      "lineNbr": 3689,
      "author": {
        "id": 1042828
      },
      "writtenOn": "2021-03-12T01:10:30Z",
      "side": 1,
      "message": "I think usually you\u0027re right that they would get suppressed for ConcurrentGC requests. But it seems complicated. Presumably the ConcurrentGC calls would be made sequentially in the HeapTaskDaemon. So I think waiting for another concurrentGC wouldn\u0027t work? I think we\u0027re counting on the request filtering for that?\n\nI think the WaitForGcToComplete call in GarbageCollectInternal doesn\u0027t really help in this respect, it just waits and then continues unconditionally. I think it currently isn\u0027t in a position to suppress GCs, since it\u0027s sometimes important to run a full GC cycle unconditionally, and sometimes not. PS2 changes its interface for that reason. But you\u0027re right that if RequestConcurrentGC initiates the later request, we\u0027re probably OK.\n\nI actually now suspect the delayed update of the malloc information was the most likely cause of what we\u0027re seeing.\n\nThis CL kind of adds logic similar to RequestConcurrentGC everywhere. I think that actually tracking the time at which we decided to GC makes this a bit easier and more robust than the flag logic. But that may be the most debatable part here.",
      "parentUuid": "f18b0208_3cc95a63",
      "range": {
        "startLine": 3689,
        "startChar": 8,
        "endLine": 3689,
        "endChar": 27
      },
      "revId": "5426f13f119397f9f66f01cff3d8db4a7853faa2",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "d990c20f_f055bb4a",
        "filename": "runtime/gc/heap.cc",
        "patchSetId": 1
      },
      "lineNbr": 3689,
      "author": {
        "id": 1258954
      },
      "writtenOn": "2021-03-15T06:11:21Z",
      "side": 1,
      "message": "I took a look at PS2, all invocations of CollectGarbageInternal(), except for one in CheckGCForNative() is with GC_NO_ANY, which I think means \"perform a GC no matter what\". So I doubt takes care of the likely case you mentioned earlier of an explicit GC running and then subsequently a concurrent GC is requested, right?\n\nThe introduction of gcs_requested_ logic only seems to take care of the case where a thread decides to perform a GC but then gets suspended, and in meantime another thread requests a concurrent GC, which is completed and then the first thread wakes up. In fact, if the first thread suspends *before* loading gcs_requested_, then even this case wouldn\u0027t be handled, right?",
      "parentUuid": "9d45f57f_698f0002",
      "range": {
        "startLine": 3689,
        "startChar": 8,
        "endLine": 3689,
        "endChar": 27
      },
      "revId": "5426f13f119397f9f66f01cff3d8db4a7853faa2",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "8d09cd9f_4497e705",
        "filename": "runtime/gc/heap.cc",
        "patchSetId": 1
      },
      "lineNbr": 3689,
      "author": {
        "id": 1042828
      },
      "writtenOn": "2021-03-19T02:15:23Z",
      "side": 1,
      "message": "I think you\u0027re right, in that there were probably few cases in which this mattered. The earlier mechanisms covered most of them. My current thinking ins that the late update of the native allocation counts was much more of an issue in practice.\n\nI updated a couple of the calls to specify an actual GC number, which should improve things a little. But for me, the main advantage of this part of the change is that it\u0027s easier to see that we\u0027re consistently filtering out redundant requests. I also think the GC_NUM_ANY addition, though it seems like a bit of a hack, is actually an improvement, in that we now have to be clear about whether we want redundant requests filtered or not. In some cases, like tests that explicitly invoke the collector, it\u0027s critical they\u0027re not filtered. In many other cases, we would like them to be filtered.\n\nIn general, any non-GC_NUM_ANY request should only be completed if the GC with the requested number hasn\u0027t happened yet. We should never get 2 GCs for the same request number. In some cases, there\u0027s still a short window between the time we note that we need a GC and we capture the GC number. But we now have a mechanism for eliminating that\u0027 ideally we should capture the GC number before checking. And in the case of the normal concurrent GC tests, we now do that.\n\nYou\u0027re right that the gcs_requested_ logic is in a sense only a heuristic to avoid creating many duplicate requests. The important test is the one in CollectGarbageInternal(). Even if we removed gcs_rested_ entirely, that would still do the filtering, though more expensively.",
      "parentUuid": "d990c20f_f055bb4a",
      "range": {
        "startLine": 3689,
        "startChar": 8,
        "endLine": 3689,
        "endChar": 27
      },
      "revId": "5426f13f119397f9f66f01cff3d8db4a7853faa2",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "b2509ae9_94dbebdc",
        "filename": "runtime/gc/heap.cc",
        "patchSetId": 1
      },
      "lineNbr": 3689,
      "author": {
        "id": 1258954
      },
      "writtenOn": "2021-03-21T11:03:23Z",
      "side": 1,
      "message": "\u003e I think you\u0027re right, in that there were probably few cases in which this mattered. The earlier mechanisms covered most of them. My current thinking ins that the late update of the native allocation counts was much more of an issue in practice.\n\u003e \n\u003e I updated a couple of the calls to specify an actual GC number, which should improve things a little. But for me, the main advantage of this part of the change is that it\u0027s easier to see that we\u0027re consistently filtering out redundant requests. I also think the GC_NUM_ANY addition, though it seems like a bit of a hack, is actually an improvement, in that we now have to be clear about whether we want redundant requests filtered or not. In some cases, like tests that explicitly invoke the collector, it\u0027s critical they\u0027re not filtered. In many other cases, we would like them to be filtered.\n\u003e \nYes, I agree reasoning about redundant requests is easier with this change.\n\n\u003e In general, any non-GC_NUM_ANY request should only be completed if the GC with the requested number hasn\u0027t happened yet. We should never get 2 GCs for the same request number. In some cases, there\u0027s still a short window between the time we note that we need a GC and we capture the GC number. But we now have a mechanism for eliminating that\u0027 ideally we should capture the GC number before checking. And in the case of the normal concurrent GC tests, we now do that.\n\nI believe you are talking about CheckConcurrentGCForJava() when you say that we capture GC number before checking if GC is required or not? But I don\u0027t think it\u0027s WAI. The new_num_bytes_allocated is already calculated *before* capturing GC number. Merely comparing *after* isn\u0027t sufficient, right? And even if it\u0027s, then shouldn\u0027t we use a fence between the two to ensure they don\u0027t get re-ordered?\n\nIIRC, we only call this function from AllocObjectWithAllocator() and the increment to num_bytes_allocated_ is also in there only. So shouldn\u0027t be too difficult to make it work?\n\n\u003e \n\u003e You\u0027re right that the gcs_requested_ logic is in a sense only a heuristic to avoid creating many duplicate requests. The important test is the one in CollectGarbageInternal(). Even if we removed gcs_rested_ entirely, that would still do the filtering, though more expensively.",
      "parentUuid": "8d09cd9f_4497e705",
      "range": {
        "startLine": 3689,
        "startChar": 8,
        "endLine": 3689,
        "endChar": 27
      },
      "revId": "5426f13f119397f9f66f01cff3d8db4a7853faa2",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "a22e5ec7_0518b277",
        "filename": "runtime/gc/heap.cc",
        "patchSetId": 1
      },
      "lineNbr": 3689,
      "author": {
        "id": 1042828
      },
      "writtenOn": "2021-03-24T00:44:14Z",
      "side": 1,
      "message": "I agree. Done by getting rid of CheckConcurrentGCForJava(), which I think actually makes the code slightly clearer.",
      "parentUuid": "b2509ae9_94dbebdc",
      "range": {
        "startLine": 3689,
        "startChar": 8,
        "endLine": 3689,
        "endChar": 27
      },
      "revId": "5426f13f119397f9f66f01cff3d8db4a7853faa2",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889"
    }
  ]
}