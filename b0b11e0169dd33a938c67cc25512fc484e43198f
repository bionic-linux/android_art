{
  "comments": [
    {
      "unresolved": false,
      "key": {
        "uuid": "9e9cff68_78149eca",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1042828
      },
      "writtenOn": "2024-10-22T22:52:18Z",
      "side": 1,
      "message": "I like the code simplification a lot.  I think this approach is probably an improvement, but not ideal. It will be significantly off in some cases:\n\nIf an allocation pattern repeats at the a rate that divides the TLAB size, you\u0027ll get really biased results. I think cputime profilers have seen this effect in the past, and generally randomize sampling as a result. I guess for long-lived threads, the GC should randomize things a bit.\n\nIf you have mostly short-lived threads doing the allocation, you\u0027ll greatly over-count the first allocation, I suspect? The total is also likely to be way high, since the TLABs won\u0027t be fully used. But then this to some extent reflects what\u0027s probably a bit of a GC problem at the moment. System server has O(450) threads. That means they use O(15MB) once they each allocate a single small object. I think we really need to reduce the 32K TLAB size.\n\nLokesh - When a thread dies, do we reuse its TLAB before the next GC? We probably should?",
      "revId": "b0b11e0169dd33a938c67cc25512fc484e43198f",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "ab03c885_bef8b9d7",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1057373
      },
      "writtenOn": "2024-10-23T20:13:19Z",
      "side": 1,
      "message": "Good point. Let me think about whether there is an easy way to avoid the biased results (e.g. blaming a random allocation in the TLAB buffer instead of the first allocation), and understand better how this compares to the current implementation.\n\nIdeal sampling is not my goal, but it would be nice not to regress the current implementation.",
      "parentUuid": "9e9cff68_78149eca",
      "revId": "b0b11e0169dd33a938c67cc25512fc484e43198f",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "0e824217_31199a29",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1057373
      },
      "writtenOn": "2024-11-06T21:42:15Z",
      "side": 1,
      "message": "I was able to reproduce the biased results pretty easily by spawning a bunch of threads and allocating at a few different call sites first thing.\n\nI updated the CL to force the slow path allocation every time and report object allocation size. That fixes the bias issues, and appears to be not too bad at all performance wise compared to the cost of taking samples when profiling is enabled.",
      "parentUuid": "ab03c885_bef8b9d7",
      "revId": "b0b11e0169dd33a938c67cc25512fc484e43198f",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "8e6de458_f87cc244",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1042828
      },
      "writtenOn": "2024-11-09T01:03:36Z",
      "side": 1,
      "message": "How does the sampling work? It turns profiling on and off? Once you get into AHeapProfile_reportAllocation, this looks pretty heavy-weight?",
      "parentUuid": "0e824217_31199a29",
      "revId": "b0b11e0169dd33a938c67cc25512fc484e43198f",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889"
    }
  ]
}