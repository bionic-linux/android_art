{
  "comments": [
    {
      "key": {
        "uuid": "95f14f3a_03297eaa",
        "filename": "/COMMIT_MSG",
        "patchSetId": 1
      },
      "lineNbr": 12,
      "author": {
        "id": 1041833
      },
      "writtenOn": "2017-03-08T16:26:23Z",
      "side": 1,
      "message": "Please extend this. It is not immediately apparent why it\u0027s OK to set it to true concurrently...",
      "range": {
        "startLine": 12,
        "startChar": 18,
        "endLine": 12,
        "endChar": 51
      },
      "revId": "0fd504032cdc88a1462df4ba9c0fe4eac4dd120e",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "e13a33c6_08c87243",
        "filename": "/COMMIT_MSG",
        "patchSetId": 1
      },
      "lineNbr": 12,
      "author": {
        "id": 1038443
      },
      "writtenOn": "2017-03-08T22:56:14Z",
      "side": 1,
      "message": "Will do. Sorry for lack of context, this change was a FYI follow-up on private conversations.",
      "parentUuid": "95f14f3a_03297eaa",
      "range": {
        "startLine": 12,
        "startChar": 18,
        "endLine": 12,
        "endChar": 51
      },
      "revId": "0fd504032cdc88a1462df4ba9c0fe4eac4dd120e",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "d37b45cb_a2bb6a09",
        "filename": "/COMMIT_MSG",
        "patchSetId": 1
      },
      "lineNbr": 14,
      "author": {
        "id": 1071150
      },
      "writtenOn": "2017-03-08T16:40:41Z",
      "side": 1,
      "message": "Does this include jsr166-tests?\n\nThese look like the ones most likely to expose an issue.",
      "range": {
        "startLine": 14,
        "startChar": 6,
        "endLine": 14,
        "endChar": 14
      },
      "revId": "0fd504032cdc88a1462df4ba9c0fe4eac4dd120e",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "482b9ead_f829443c",
        "filename": "/COMMIT_MSG",
        "patchSetId": 1
      },
      "lineNbr": 14,
      "author": {
        "id": 1038443
      },
      "writtenOn": "2017-03-08T22:56:14Z",
      "side": 1,
      "message": "Yes it does.",
      "parentUuid": "d37b45cb_a2bb6a09",
      "range": {
        "startLine": 14,
        "startChar": 6,
        "endLine": 14,
        "endChar": 14
      },
      "revId": "0fd504032cdc88a1462df4ba9c0fe4eac4dd120e",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "76cb2125_ad82d5e2",
        "filename": "compiler/optimizing/intrinsics_arm.cc",
        "patchSetId": 1
      },
      "lineNbr": 2728,
      "author": {
        "id": 1071150
      },
      "writtenOn": "2017-03-08T16:40:41Z",
      "side": 1,
      "message": "For the reader, these intrinsics would slightly clearer with a comment along the lines of \"Get thread\u0027s interrupted flag and clear it as described by java.lang.Thread.interrupted()\".",
      "revId": "0fd504032cdc88a1462df4ba9c0fe4eac4dd120e",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "0193afa4_dccf0e80",
        "filename": "runtime/thread.cc",
        "patchSetId": 1
      },
      "lineNbr": 2255,
      "author": {
        "id": 1042828
      },
      "writtenOn": "2017-03-09T00:39:04Z",
      "side": 1,
      "message": "In addition to Orion\u0027s comment, it seems that this also just introduces a data race with Interrupted(), which it seems can read this concurrently from the target thread.\n\nThere may be a way to do this by turning interrupted into an atomic, but the ways I can immediately think of run into memory ordering issues. Consider the (admittedly absurd) case in which two threads interrupt each other, and then call interrupt(). One has to see the flag set. Seq_cst atomic operations and an exchange in Interrupted might do, but is that a win?",
      "range": {
        "startLine": 2255,
        "startChar": 2,
        "endLine": 2255,
        "endChar": 28
      },
      "revId": "0fd504032cdc88a1462df4ba9c0fe4eac4dd120e",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "98bf3e85_8715534f",
        "filename": "runtime/thread.cc",
        "patchSetId": 1
      },
      "lineNbr": 2255,
      "author": {
        "id": 1038443
      },
      "writtenOn": "2017-03-09T14:02:30Z",
      "side": 1,
      "message": "Yes, please see PS2 for thread.cc, which now conditionally updates the flag. I believe this makes us safe.",
      "parentUuid": "0193afa4_dccf0e80",
      "range": {
        "startLine": 2255,
        "startChar": 2,
        "endLine": 2255,
        "endChar": 28
      },
      "revId": "0fd504032cdc88a1462df4ba9c0fe4eac4dd120e",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "12ddda77_f83772c5",
        "filename": "runtime/thread.cc",
        "patchSetId": 1
      },
      "lineNbr": 2255,
      "author": {
        "id": 1042828
      },
      "writtenOn": "2017-03-09T19:06:31Z",
      "side": 1,
      "message": "I suspect you\u0027re right that this eliminates the bugs that show up in an interleaving-based, sequentially consistent execution.\n\nBut I also think this still allows concurrent access to tls32_.interrupted, since Thread::Interrupt and Thread::Interrupted can be called concurrently. By C++ rules, that\u0027s undefined behavior. In practice, it means that we have to worry about various potential C++ compiler optimizations that are now unsound because we\u0027re violating the compiler\u0027s assumptions.\n\nThat part could be fixed by making interrupted atomic and using memory_order_relaxed accesses. But I don\u0027t think that\u0027s really sufficient, in that you want memory ordering guarantees here. The Java spec is not as clear on this as it should be.\n\nThe most important case is the one in which Thread 1 sets up a (possibly trivial) data structure D, then interrupts Thread 2, which calls Interrupted(), and reads D. With your change, strengthened to use memory_order_relaxed, D is no long guaranteed to be correctly visible in Thread 2. I wouldn\u0027t be surprised if this violates some of our own internal assumptions.\n\nThis could be fixed by using memory_order_acquire loads and memory_order_release stores. But that still doesn\u0027t handle the two-threads-interrupting-each-other scenario from the previous message, so we really want memory_order_seq_cst. (Which generates the same code on arm64, but is slower on the store side for arm32 or x86, which probably doesn\u0027t matter.)\n\nAt that point, we need an acquire load or fence on every load access, and a bit more than that for every store. Is it still a win? Possibly, if Interrupted() or IsInterrupted() are far more frequently called than everything else. Which seems plausible, but I\u0027m not sure. I was initially concerned about the monitor code that reads this, but that should only be wait(), which is expensive enough not to matter.\n\nOr we could argue that the spec doesn\u0027t really guarantee this ordering. But I think that\u0027s pretty clearly unintentional, and we probably have code ourselves that assumes it.",
      "parentUuid": "98bf3e85_8715534f",
      "range": {
        "startLine": 2255,
        "startChar": 2,
        "endLine": 2255,
        "endChar": 28
      },
      "revId": "0fd504032cdc88a1462df4ba9c0fe4eac4dd120e",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "9d6e8b54_13f96a5d",
        "filename": "runtime/thread.cc",
        "patchSetId": 1
      },
      "lineNbr": 2255,
      "author": {
        "id": 1038443
      },
      "writtenOn": "2017-03-09T22:39:14Z",
      "side": 1,
      "message": "\u003e I suspect you\u0027re right that this eliminates the bugs that show up\n \u003e in an interleaving-based, sequentially consistent execution.\n \u003e \n \u003e But I also think this still allows concurrent access to\n \u003e tls32_.interrupted, since Thread::Interrupt and Thread::Interrupted\n \u003e can be called concurrently. By C++ rules, that\u0027s undefined\n \u003e behavior. In practice, it means that we have to worry about various\n \u003e potential C++ compiler optimizations that are now unsound because\n \u003e we\u0027re violating the compiler\u0027s assumptions.\n\nI assume you mean the C++ compiler? For ART\u0027s optimizing compiler we do control the code generation, and can make sure the read and sore are sequential.\n\n \u003e \n \u003e That part could be fixed by making interrupted atomic and using\n \u003e memory_order_relaxed accesses. But I don\u0027t think that\u0027s really\n \u003e sufficient, in that you want memory ordering guarantees here. The\n \u003e Java spec is not as clear on this as it should be.\n \u003e \n \u003e The most important case is the one in which Thread 1 sets up a\n \u003e (possibly trivial) data structure D, then interrupts Thread 2,\n \u003e which calls Interrupted(), and reads D. With your change,\n \u003e strengthened to use memory_order_relaxed, D is no long guaranteed\n \u003e to be correctly visible in Thread 2. I wouldn\u0027t be surprised if\n \u003e this violates some of our own internal assumptions.\n\nAre you describing a Java scenario, or a C++ scenario? Also, are you implying that regardless if it\u0027s C++/Java, we may rely on the current memory barrier behavior of \ninterrupt/interrupted for concurrent data structures not marked volatile? Is that specified by Java?\n\n \u003e \n \u003e This could be fixed by using memory_order_acquire loads and\n \u003e memory_order_release stores. But that still doesn\u0027t handle the\n \u003e two-threads-interrupting-each-other scenario from the previous\n \u003e message, so we really want memory_order_seq_cst. (Which generates\n \u003e the same code on arm64, but is slower on the store side for arm32\n \u003e or x86, which probably doesn\u0027t matter.)\n \u003e \n \u003e At that point, we need an acquire load or fence on every load\n \u003e access, and a bit more than that for every store. Is it still a\n \u003e win? Possibly, if Interrupted() or IsInterrupted() are far more\n \u003e frequently called than everything else. Which seems plausible, but\n \u003e I\u0027m not sure. I was initially concerned about the monitor code that\n \u003e reads this, but that should only be wait(), which is expensive\n \u003e enough not to matter.\n \u003e \n \u003e Or we could argue that the spec doesn\u0027t really guarantee this\n \u003e ordering. But I think that\u0027s pretty clearly unintentional, and we\n \u003e probably have code ourselves that assumes it.",
      "parentUuid": "12ddda77_f83772c5",
      "range": {
        "startLine": 2255,
        "startChar": 2,
        "endLine": 2255,
        "endChar": 28
      },
      "revId": "0fd504032cdc88a1462df4ba9c0fe4eac4dd120e",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "b628297a_144d61d6",
        "filename": "runtime/thread.cc",
        "patchSetId": 1
      },
      "lineNbr": 2255,
      "author": {
        "id": 1042828
      },
      "writtenOn": "2017-03-09T23:10:23Z",
      "side": 1,
      "message": "\u003e I assume you mean the C++ compiler? For ART\u0027s optimizing\n\u003e compiler we do control the code generation, and can make\n\u003e sure the read and sore are sequential.\n\nYes, the C++ compiler. Java is more tolerant of data races, though the ordering issues below would still apply.\n\n\u003e Are you describing a Java scenario, or a C++ scenario?\n\u003e Also, are you implying that regardless if it\u0027s C++/Java,\n\u003e we may rely on the current memory barrier behavior of\n\u003e interrupt/interrupted for concurrent data structures\n\u003e not marked volatile? Is that specified by Java?\n\nReally either. In both languages, thread communication\nmechanisms guarantee ordering. And this can clearly be used to\ncommunicate between threads. A design goal was to ensure\nthat programmers who avoid data races and don\u0027t explicitly\nopt out see sequentially consistent (interleaving) behavior,\nwhich requires this kind of visibility.\n\nHowever, this mechanism is obscure enough that the language\nspec doesn\u0027t explicitly guarantee the ordering, so things\nare up for debate.\n\nThe data in question is usually not marked volatile, just as\nit isn\u0027t if accesses are protected by a lock. It\u0027s the lock release\nfollowed by lock acquisition that ensure visibility.",
      "parentUuid": "9d6e8b54_13f96a5d",
      "range": {
        "startLine": 2255,
        "startChar": 2,
        "endLine": 2255,
        "endChar": 28
      },
      "revId": "0fd504032cdc88a1462df4ba9c0fe4eac4dd120e",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "734a6d5f_db08db1c",
        "filename": "runtime/thread.h",
        "patchSetId": 1
      },
      "lineNbr": 580,
      "author": {
        "id": 1071150
      },
      "writtenOn": "2017-03-08T16:40:41Z",
      "side": 1,
      "message": "Straying whitespace needs rounding up and dressing down.",
      "range": {
        "startLine": 580,
        "startChar": 0,
        "endLine": 580,
        "endChar": 2
      },
      "revId": "0fd504032cdc88a1462df4ba9c0fe4eac4dd120e",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "a30f41dc_2879b466",
        "filename": "runtime/thread.h",
        "patchSetId": 1
      },
      "lineNbr": 1433,
      "author": {
        "id": 1071150
      },
      "writtenOn": "2017-03-08T16:40:41Z",
      "side": 1,
      "message": "is_interrupted might be slightly less grammatically ambiguous, the field above is is_gc_marking, but fine as-is also.",
      "revId": "0fd504032cdc88a1462df4ba9c0fe4eac4dd120e",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889",
      "unresolved": false
    }
  ]
}